# -*- coding: utf-8 -*-
"""HAND GESTURE RECOGNITION PROJECT IPMV

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/113NdmFiv3__iB_46HjUx9XpKeAEyRVdh
"""

#INSTALLING MEDIAPIPE EXTENSION
!python -m pip install mediapipe

#INSTALLING MEDIAPIPE NUMPY EXTENSION
!pip install opencv-python mediapipe numpy

#INSTALLING MEDIAPIPE AND OPENCV EXTENSION
!pip install opencv-python opencv-contrib-python mediapipe numpy

#INSTALLING PANDAS MATPLOTLIB EXTENSION
!pip install matplotlib pandas scikit-learn

#INSTALLING LATEST VERSION OF MEDIAPIPE
!pip install mediapipe==0.10.11

!pip install mediapipe

# STEP 1: Install dependencies
!pip install mediapipe==0.10.11 opencv-python pyngrok==4.1.1

# STEP 2: Import required libraries
import cv2
import mediapipe as mp
import numpy as np
from google.colab.output import eval_js
from base64 import b64decode
from google.colab.patches import cv2_imshow
from IPython.display import display, Javascript

# STEP 3: JavaScript Webcam Capture for Google Colab
def capture_image():
    js = Javascript('''
    async function captureImage() {
        const div = document.createElement('div');
        document.body.appendChild(div);
        const video = document.createElement('video');
        div.appendChild(video);
        video.style.display = 'block';

        const stream = await navigator.mediaDevices.getUserMedia({video: true});
        video.srcObject = stream;
        await video.play();

        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

        return new Promise((resolve) => {
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            stream.getVideoTracks()[0].stop();
            resolve(canvas.toDataURL('image/jpeg'));
        });
    }
    ''')
    display(js)
    data = eval_js('captureImage()')
    binary = b64decode(data.split(',')[1])
    np_arr = np.frombuffer(binary, dtype=np.uint8)
    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
    return img

# STEP 4: Setup MediaPipe Hands
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# STEP 5: Define gesture recognition logic with improved accuracy
def recognize_gesture(landmarks):
    tips_ids = [4, 8, 12, 16, 20]
    finger_states = []

    for tip_id in tips_ids[1:]:
        tip = landmarks.landmark[tip_id].y
        pip = landmarks.landmark[tip_id - 2].y
        finger_states.append(tip < pip)

    thumb_tip = landmarks.landmark[4]
    thumb_ip = landmarks.landmark[3]
    thumb_state = thumb_tip.x > thumb_ip.x

    if all(finger_states) and thumb_state:
        return "Open Palm üñê"
    elif finger_states[0] and finger_states[1] and not any(finger_states[2:]):
        return "Peace ‚úå"
    elif not any(finger_states) and not thumb_state:
        return "Fist ‚úä"
    elif not any(finger_states) and thumb_state:
        return "Thumbs Up üëç"
    elif finger_states[0] and not any(finger_states[1:]) and not thumb_state:
        return "Pointing ‚òùÔ∏è"
    else:
        return "Unknown Gesture ü§î"

# STEP 6: Capture an Image and Detect Gesture
with mp_hands.Hands(
    static_image_mode=True,
    max_num_hands=1,
    min_detection_confidence=0.7) as hands:
    try:
        frame = capture_image()
        frame = cv2.flip(frame, 1)
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(image)
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                gesture = recognize_gesture(hand_landmarks)
                cv2.putText(image, f"Gesture: {gesture}", (50, 50),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
        else:
            gesture = "No hand detected"
            cv2.putText(image, gesture, (50, 50),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)

        cv2_imshow(image)
    except Exception as e:
        print(f"Error: {e}")